Estes comentários são refetentes ao arquivo utilities.py

7 -> nesta linha eu decidi criar o meu próprio leitor de arquivo, ao invés de utilizar o que foi fornecido pelo dataset.
    eu adicionei no arquivo dataset.csv os index's: Index e Tongue twister
    como eu vou utilizar apenas os trava línguas, eu preciso apenas de sua coluna. para isto, eu utilizei o seguinte material: https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html#min-tut-10-text
    porém, eu fiquei quebrando a cabeça, pois ainda aparecia os índices, coisa que eu não desejava, além disto, já tinha implementado o material anterior
    felizmente, eu descobri que esses índices são do próprio pandas, e não os índices do csv
    mais tarde, para manipular estes dados, percebi que era melhor usar listas do que um dataframe

19 -> counter serve para realizar a contagem de elementos em uma estrutura de dados. A cada vez que é usado, retorna um objeto, que contém um dicionário com
    todos os caracteres e quantas veses ele se repete.
    Quando se usa o .most_common(), retorna tupla que contém o char mais repetido, junto com a quantidade de vezes que ele aparece, no caso, na lista.
    Counter(frase.lower().replace(' ', '')) for frase in frases).most_common(2), deste modo, está retornando os 2 caracteres que mais se repetem em todos os 605 trava-línguas.
    for frase in db:
        lista.append(Counter(frase.lower().replace(' ', ''))).most_common(2)), já assim retorna os 2 caracteres que mais se repetem para cada uma das 605 frases
    Por este motivo, fui forçado a utilizar o for normal, sem list compration, pois a medida de complexidade de um trava língua é feita, obviamente, por cada
    unidade, e não pela totalidade deles.
    Agora eu percebi que posso usar list comprehation com o Counter, deste modo: [Counter(frase.lower().replace(' ', ''))]. Assim, retorna uma lista das letras
    que mais se repetem para cada trava-língua.






